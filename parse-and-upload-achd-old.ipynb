{
 "metadata": {
  "name": "",
  "signature": "sha256:86f3b017822807bcc533be54b7eb5ea3640af38ec9bfa19f06071b199dde8463"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Execute this cell to define the functions for calling the Fluxtream upload API for the \n",
      "# credentials entered below\n",
      "import json, subprocess\n",
      "\n",
      "# By default, the upload function will send data to the main server at fluxtream.org.  \n",
      "# If you want to have this use a different fluxtream server, change it here\n",
      "# and make sure the username and password entered below are valid on that server.\n",
      "global fluxtream_server\n",
      "fluxtream_server = \"fluxtream.org\"\n",
      "\n",
      "def setup_fluxtream_credentials():\n",
      "    # Call the Fluxtream guest API, documented at \n",
      "    #   https://fluxtream.atlassian.net/wiki/display/FLX/BodyTrack+server+APIs#BodyTrackserverAPIs-GettheIDfortheguest\n",
      "\n",
      "    # Make sure it works and harvest the Guest ID for future use\n",
      "    global fluxtream_server, fluxtream_username, fluxtream_password, fluxtream_guest_id\n",
      "\n",
      "    # Make sure we have fluxtream credentials set properly\n",
      "    if not('fluxtream_server' in globals() and \n",
      "           'fluxtream_username' in globals() and\n",
      "           'fluxtream_password' in globals()):\n",
      "        raise Exception(\"Need to enter Fluxtream credentials before uploading data.  See above.\")\n",
      "\n",
      "    cmd = ['curl', '-v']\n",
      "    cmd += ['-u', '%s:%s' % (fluxtream_username, fluxtream_password)]\n",
      "    cmd += ['https://%s/api/guest' % fluxtream_server]\n",
      "\n",
      "    result_str = subprocess.check_output(cmd)\n",
      "    #print '  Result=%s' % (result_str)\n",
      "\n",
      "    try:\n",
      "        response = json.loads(result_str)\n",
      "\n",
      "        if 'id' in response:\n",
      "            fluxtream_guest_id = int(response['id'])\n",
      "        else:\n",
      "            raise Exception('Received unexpected response %s while trying to check credentials for %s on %s' % (response, \n",
      "                                                                                                            fluxtream_username, \n",
      "                                                                                                            fluxtream_server))\n",
      "\n",
      "        print 'Verified credentials for user %s on %s work. Guest ID=%d' % (fluxtream_username, fluxtream_server, fluxtream_guest_id)\n",
      "    except:\n",
      "        print \"Attempt to check credentials of user %s failed\" % (fluxtream_username)\n",
      "        print \"Server returned response of: %s\" % (result_str)\n",
      "        print \"Check login to https://%s works and re-enter your Fluxtream credentials above\" % (fluxtream_server)\n",
      "        raise\n",
      "    \n",
      "def fluxtream_upload(dev_nickname, channel_names, data):\n",
      "    global fluxtream_server, fluxtream_username, fluxtream_password\n",
      "    \n",
      "    # Make sure we have some data to send\n",
      "    if data == None or len(data)<1:\n",
      "        print 'Nothing to upload to %s %s' % (dev_nickname, channel_names)        \n",
      "        return\n",
      "\n",
      "    # Make sure we have fluxtream credentials set properly\n",
      "    if not('fluxtream_server' in globals() and \n",
      "           'fluxtream_username' in globals() and\n",
      "           'fluxtream_password' in globals()):\n",
      "        raise Exception(\"Need to enter Fluxtream credentials before uploading data.  See above.\")\n",
      "\n",
      "    # Send to BodyTrack upload API, documented at \n",
      "    #   https://fluxtream.atlassian.net/wiki/display/FLX/BodyTrack+server+APIs#BodyTrackserverAPIs-Storingdata\n",
      "    cmd = ['curl', '-v']\n",
      "    cmd += ['-u', '%s:%s' % (fluxtream_username, fluxtream_password)]\n",
      "    cmd += ['-d', 'dev_nickname=%s' % dev_nickname]\n",
      "    cmd += ['-d', 'channel_names=%s' % json.dumps(channel_names)]\n",
      "    cmd += ['-d', 'data=%s' % json.dumps(data)]\n",
      "    cmd += ['https://%s/api/bodytrack/upload' % fluxtream_server]\n",
      "\n",
      "    result_str = subprocess.check_output(cmd)\n",
      "    #print '  Result=%s' % (result_str)\n",
      "\n",
      "    try:\n",
      "        response = json.loads(result_str)\n",
      "        if response['result'] != 'OK':\n",
      "            print 'Tried to upload channels >%s<' % json.dumps(channel_names)\n",
      "            print 'Tried to upload data >%s<' % json.dumps(data)\n",
      "            raise Exception('Received non-OK response %s while trying to upload to %s' % (response, dev_nickname))\n",
      "        \n",
      "        print 'Upload to %s %s (%d rows, %d to %d) succeeded' % (dev_nickname, channel_names, len(data), data[0][0], data[-1][0])\n",
      "    except:\n",
      "        print \"Attempt to upload to %s as user %s failed. Check that your credentials are ok\" % (fluxtream_server, \n",
      "                                                                                                 fluxtream_username)\n",
      "        print \"Server returned response: %s\" % (result_str)\n",
      "        raise\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "global fluxtream_username, fluxtream_password\n",
      "fluxtream_username = \"achd\"\n",
      "fluxtream_password = \"achdmirror\"\n",
      "setup_fluxtream_credentials()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Verified credentials for user achd on fluxtream.org work. Guest ID=1968\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Point:\n",
      "    def __init__(self, x, y):\n",
      "        self.x = x\n",
      "        self.y = y\n",
      "        \n",
      "    def __sub__(self, rhs):\n",
      "        return Point(self.x - rhs.x, self.y - rhs.y)\n",
      "        \n",
      "    def __repr__(self):\n",
      "        return 'Point2(%g, %g)' % (self.x, self.y)\n",
      "\n",
      "class Bbox:\n",
      "    def __init__(self, str):\n",
      "        (self.left, self.top, self.right, self.bottom) = [float(e) for e in str.split(',')]\n",
      "        \n",
      "    def __repr__(self):\n",
      "        return 'Bbox(%g, %g, %g, %g)' % (self.top, self.left, self.bottom, self.right)\n",
      "    \n",
      "    def center(self):\n",
      "        return Point(0.5 * (self.left + self.right), 0.5 * (self.top + self.bottom))\n",
      "    \n",
      "    def width(self):\n",
      "        return self.right - self.left\n",
      "    \n",
      "    def height(self):\n",
      "        return self.bottom - self.top\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Algorithm:\n",
      "\n",
      "Find centers of text matching 00:00 ... 23:00\n",
      "Compute row centers 00:00 ... 23:00, plus two rows on top for headers\n",
      "Find centers of text that lines up with top header row.  These are column locations\n",
      "Add center of 00:00 to columns\n",
      "\n",
      "Iterate through all text.  If text lines up with a row, install it in the closest column according to center\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import datetime\n",
      "from dateutil import tz\n",
      "\n",
      "pgh_tz = tz.gettz(\"America/New_York\")\n",
      "\n",
      "log_lines = []\n",
      "\n",
      "def reset_log():\n",
      "    global log_lines\n",
      "    log_lines = []\n",
      "    \n",
      "def log(msg):\n",
      "    global log_lines\n",
      "    print msg\n",
      "    log_lines.append(datetime.datetime.now(tz.tzlocal()).strftime('%Y-%m-%d %H:%M:%S%z') + ' ' + msg)\n",
      "    \n",
      "def get_log():\n",
      "    return '\\n'.join(log_lines)\n",
      "    \n",
      "def epoch_time(dt):\n",
      "    epoch = datetime.datetime(1970, 1, 1, tzinfo=tz.tzutc())\n",
      "    return (dt - epoch).total_seconds()    \n",
      "\n",
      "def sanitize_name(name):\n",
      "    return re.sub('\\W', '_', name.encode('utf8'))\n",
      "\n",
      "def process_achd_site(achd_site, base_datetime, achd_table):\n",
      "    # Replace non-alphanum with underscores in achd_site\n",
      "    devname = \"ACHD_%s\" % (re.sub('\\W', '_',achd_site))\n",
      "    channel_names = []\n",
      "\n",
      "    # Process the header into channel names\n",
      "    for i in range (1, len(achd_table[0])):\n",
      "        channel_names.append(sanitize_name('%s_%s' % (achd_table[0][i], achd_table[1][i])))\n",
      "    \n",
      "    log(\"Found devname=%s, channels=%s, starting %s\" % (devname, channel_names, base_datetime))\n",
      "    \n",
      "    rowcount = 0;\n",
      "    data_cols = [[] for x in range(0, len(channel_names))]\n",
      "    \n",
      "    for i in range (2, len(achd_table)):\n",
      "        row = achd_table[i]\n",
      "        \n",
      "        # Add base_datetime to the first column of the row, which is the local time within that date\n",
      "        local_row_hour =  datetime.datetime.strptime(row[0], '%H:%M')\n",
      "        local_row_datetime = base_datetime.replace(hour= local_row_hour.hour).replace(tzinfo=pgh_tz)\n",
      "        unix_ts = epoch_time(local_row_datetime)\n",
      "        \n",
      "        \n",
      "        for j in range (1, len(row)):\n",
      "            try:\n",
      "                data_row = [unix_ts]\n",
      "                val_str = row[j].encode('utf8')\n",
      "                if \" \" in val_str:\n",
      "                    # condensation\n",
      "                    val_elts = val_str.split(' ')\n",
      "                    val_str = val_elts[0]\n",
      "                    annotation = val_elts[1]\n",
      "                    #print \"Ignoring annotation %s on %s, using %s [%d][%d]\" % (annotation, row[j], val_str, i, j)\n",
      "            \n",
      "                data_row.append(float(val_str))\n",
      "                data_cols[j-1].append(data_row)\n",
      "            except:\n",
      "                pass\n",
      "            \n",
      "    for i in range (0, len(channel_names)):\n",
      "        fluxtream_upload(devname, [ channel_names[i] ], data_cols[i])\n",
      "        log(\"Uploaded %d samples to devname=%s, channels=%s, starting %s\" % \n",
      "            (len(data_cols[i]), devname, channel_names[i], base_datetime))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import datetime, math, os, re, xml.dom.minidom\n",
      "\n",
      "def parse_textline(textline):\n",
      "    bbox = Bbox(textline.getAttribute('bbox'))\n",
      "    text = ''.join([elt.firstChild.nodeValue for elt in textline.getElementsByTagName('text')])\n",
      "    return {'bbox':bbox, 'text': text}\n",
      "\n",
      "def process_page(page):\n",
      "    textlines = [parse_textline(textline) for textline in page.getElementsByTagName('textline')]\n",
      "\n",
      "    # Find site\n",
      "    site = None\n",
      "\n",
      "    for (i, textline) in enumerate(textlines):\n",
      "        if textline['text'].strip() == 'Site:':\n",
      "            site_textline = textlines[i + 1]\n",
      "            deltapos = textline['bbox'].center() - site_textline['bbox'].center()\n",
      "        \n",
      "            if abs(deltapos.y) > 3:\n",
      "                raise Exception('Confused about y location while trying to locate site')\n",
      "        \n",
      "            if deltapos.x > 0 or deltapos.x < -100:\n",
      "                raise Exception('Confused about x location while trying to locate site')\n",
      "        \n",
      "            if site:\n",
      "                raise Exception('Found more than one site?')\n",
      "        \n",
      "            site = site_textline['text'].strip()\n",
      "\n",
      "    if not site:\n",
      "        raise Exception(\"Couldn't parse site\")\n",
      "\n",
      "    log('Site: %s' % site)\n",
      "\n",
      "    # Find date\n",
      "    date = None\n",
      "    for textline in textlines:\n",
      "        if re.match(r'\\d+/\\d+/\\d+$', textline['text'].strip()):\n",
      "            if date:\n",
      "                raise Exception('Found more than one date?')\n",
      "            date = datetime.datetime.strptime(textline['text'].strip(), '%m/%d/%Y')\n",
      "\n",
      "    if not date:\n",
      "        raise Exception(\"Couldn't find date\")\n",
      "\n",
      "    log('Date: %s' % date)\n",
      "\n",
      "    toprow = None\n",
      "    bottomrow = None\n",
      "    columns = []\n",
      "\n",
      "    # Find row locations\n",
      "    for textline in textlines:\n",
      "        if textline['text'].strip() == '00:00':\n",
      "            if toprow:\n",
      "                raise Exception('Found more than one toprow?')\n",
      "            toprow = textline['bbox'].center().y\n",
      "            columns.append(textline['bbox'].center().x)\n",
      "        if textline['text'].strip() == '23:00':\n",
      "            if bottomrow:\n",
      "                raise Exception('Found more than one bottomrow?')\n",
      "            bottomrow = textline['bbox'].center().y\n",
      "\n",
      "    if not toprow or not bottomrow:\n",
      "        raise Exception(\"Couldn't find row landmarks\")\n",
      "\n",
      "    def compute_row(textline):\n",
      "        fraction = (toprow - textline['bbox'].center().y) / float(toprow - bottomrow)\n",
      "        row = round((fraction * 23) + 2)\n",
      "        if (row < 0 or row > 25):\n",
      "            return None\n",
      "        return int(row)\n",
      "\n",
      "    # Find columns\n",
      "    for textline in textlines:\n",
      "        if 0 == compute_row(textline):\n",
      "            columns.append(textline['bbox'].center().x)\n",
      "\n",
      "    columns = sorted(columns)\n",
      "\n",
      "    def compute_col(textline):\n",
      "        x = textline['bbox'].center().x\n",
      "        best = 0\n",
      "        for i in range(0, len(columns)):\n",
      "            if abs(x - columns[i]) < abs(x - columns[best]):\n",
      "                best = i\n",
      "        return best\n",
      "\n",
      "    table = [[None] * len(columns) for row in range(0, 26)]\n",
      "\n",
      "    # Build table\n",
      "    # Find columns\n",
      "    for textline in textlines:\n",
      "        row = compute_row(textline)\n",
      "        if row != None:\n",
      "            col = compute_col(textline)\n",
      "            table[row][col] = textline['text'].strip()\n",
      "\n",
      "    process_achd_site(site, date, table)\n",
      "    \n",
      "def process_doc(doc):\n",
      "    for (pageno, page) in enumerate(doc.getElementsByTagName('page')):\n",
      "        log('-------------------------------------------------------------------------------')\n",
      "        log('Processing page %d' % pageno)\n",
      "        process_page(page)\n",
      "        log('-------------------------------------------------------------------------------')\n",
      "\n",
      "# Must install PDFMiner for pdf2txt.py\n",
      "# Ubuntu 12.04LTS: sudo apt-get install python-pdfminer\n",
      "\n",
      "def process_pdf(pdf_path):\n",
      "    done_dir = 'upload-to-fluxtream'\n",
      "    try:\n",
      "        os.mkdir(done_dir)\n",
      "    except OSError:\n",
      "        pass\n",
      "    done_path = done_dir + '/' + os.path.basename(os.path.splitext(pdf_path)[0]) + '.successful-upload'\n",
      "    if os.path.exists(done_path):\n",
      "        log('%s already uploaded, skipping' % pdf_path)\n",
      "        return\n",
      "    reset_log()\n",
      "    log('Parsing and uploading %s' % pdf_path)\n",
      "    log('Converting %s to xml' % pdf_path)\n",
      "    xml_content = subprocess.check_output(['pdf2txt', '-t', 'xml', pdf_path])\n",
      "    print 'pdf length %d converted to xml length %d' % (os.stat(pdf_path).st_size, len(xml_content))\n",
      "\n",
      "    doc = xml.dom.minidom.parseString(xml_content)\n",
      "    process_doc(doc)\n",
      "    open(done_path + '.tmp', 'w').write(get_log())\n",
      "    os.rename(done_path + '.tmp', done_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "\n",
      "for pdf in sorted(glob.glob('mirror/*.PDF')):\n",
      "    process_pdf(pdf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "mirror/DailySummary-2014-05-02-17:05:11-0400.PDF already uploaded, skipping\n",
        "mirror/DailySummary-2014-05-07-00:35:06-0400.PDF already uploaded, skipping\n",
        "mirror/DailySummary-2014-05-10-00:35:06-0400.PDF already uploaded, skipping\n",
        "mirror/DailySummary-2014-05-16-00:35:04-0400.PDF already uploaded, skipping\n",
        "mirror/DailySummary-2014-05-22-00:35:10-0400.PDF already uploaded, skipping\n",
        "mirror/DailySummary-2014-05-28-00:35:08-0400.PDF already uploaded, skipping\n",
        "mirror/DailySummary-2014-05-29-07:35:09-0400.PDF already uploaded, skipping\n",
        "mirror/DailySummary-2014-05-29-13:35:40-0400.PDF already uploaded, skipping\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}